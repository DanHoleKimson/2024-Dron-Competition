{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO/damECCRC6/g5s53mjlgv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["1. 환경설정 및 필요한 라이브러리 설치  "],"metadata":{"id":"NMkHfNYhE6u8"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yc5LpffIEbWM","executionInfo":{"status":"ok","timestamp":1717690163899,"user_tz":-540,"elapsed":36398,"user":{"displayName":"김대현","userId":"14081338161671999548"}},"outputId":"bd1b05cd-12f0-4784-cdf8-3b5b1ac37ba7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.10/dist-packages (0.16.1)\n","Collecting tf2onnx\n","  Downloading tf2onnx-1.16.1-py3-none-any.whl (455 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.8/455.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting openvino-dev\n","  Downloading openvino_dev-2024.1.0-15008-py3-none-any.whl (4.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.1)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub) (2.15.1)\n","Collecting onnx>=1.4.1 (from tf2onnx)\n","  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (2.31.0)\n","Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from openvino-dev) (0.7.1)\n","Collecting networkx<=3.1.0 (from openvino-dev)\n","  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting openvino-telemetry>=2023.2.1 (from openvino-dev)\n","  Downloading openvino_telemetry-2024.1.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from openvino-dev) (6.0.1)\n","Collecting openvino==2024.1.0 (from openvino-dev)\n","  Downloading openvino-2024.1.0-15008-cp310-cp310-manylinux2014_x86_64.whl (38.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.7/38.7 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2024.6.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n","Installing collected packages: openvino-telemetry, openvino, onnx, networkx, tf2onnx, openvino-dev\n","  Attempting uninstall: networkx\n","    Found existing installation: networkx 3.3\n","    Uninstalling networkx-3.3:\n","      Successfully uninstalled networkx-3.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.3.0+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed networkx-3.1 onnx-1.16.1 openvino-2024.1.0 openvino-dev-2024.1.0 openvino-telemetry-2024.1.0 tf2onnx-1.16.1\n"]}],"source":["# 환경 설정 및 필요한 라이브러리 설치\n","!pip install tensorflow tensorflow_hub tf2onnx openvino-dev"]},{"cell_type":"markdown","source":["2. Google Drive 마운트  "],"metadata":{"id":"xkXDLr2ZFBrk"}},{"cell_type":"code","source":["# Google Drive 마운트\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y_7D8I51ElHp","executionInfo":{"status":"ok","timestamp":1717690237427,"user_tz":-540,"elapsed":17013,"user":{"displayName":"김대현","userId":"14081338161671999548"}},"outputId":"57a2039b-07b3-4266-95f6-8c788cee6964"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["3. 로컬 데이터셋 준비  "],"metadata":{"id":"0wn0hnJtFFjG"}},{"cell_type":"code","source":["# 데이터셋 준비\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import os\n","import numpy as np\n","import pickle  # pickle 임포트 추가\n","\n","# 데이터셋 경로 설정 (Google Drive에 있는 경로)\n","train_dir = '/content/drive/MyDrive/Datas/train'  # 'train' 폴더 경로\n","validation_dir = '/content/drive/MyDrive/Datas/valid'  # 'validation' 폴더 경로\n","\n","# 클래스 레이블 추출 및 저장 (한 번 실행 후 주석 처리 가능)\n","class_names = sorted(os.listdir(train_dir))\n","with open('/content/drive/MyDrive/class_names.pkl', 'wb') as f:\n","    pickle.dump(class_names, f)\n","\n","# 클래스 레이블 로드\n","with open('/content/drive/MyDrive/class_names.pkl', 'rb') as f:\n","    class_names = pickle.load(f)\n","\n","# 데이터 전처리 함수\n","def preprocess(image, label):\n","    image = tf.image.resize(image, (224, 224)) / 255.0\n","    return image, label\n","\n","# 이미지 로드 및 전처리 함수\n","def load_and_preprocess_image(image_path):\n","    image = tf.io.read_file(image_path)\n","    image = tf.image.decode_jpeg(image, channels=3)\n","    return preprocess(image, tf.constant(0))\n","\n","# 데이터셋 생성 함수\n","def create_dataset(directory):\n","    dataset = tf.data.Dataset.list_files(os.path.join(directory, '*/*'))\n","    dataset = dataset.map(lambda x: load_and_preprocess_image(x))\n","    return dataset\n","\n","# 데이터셋 크기 계산\n","train_dataset_size = len(tf.io.gfile.glob(train_dir + '/*/*'))\n","validation_dataset_size = len(tf.io.gfile.glob(validation_dir + '/*/*'))\n","\n","# 로컬 데이터셋 로드 및 배치 처리\n","batch_size = 32\n","buffer_size = train_dataset_size  # 셔플 버퍼 크기를 train 데이터셋의 크기로 설정\n","ds_train = create_dataset(train_dir).shuffle(buffer_size).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n","ds_val = create_dataset(validation_dir).shuffle(buffer_size).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n","\n","\n","# 로컬 데이터셋 로드 및 배치 처리\n","batch_size = 32\n","ds_train = create_dataset(train_dir).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n","ds_val = create_dataset(validation_dir).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n"],"metadata":{"id":"cR-E_mB3EnnV","executionInfo":{"status":"ok","timestamp":1717690289169,"user_tz":-540,"elapsed":10848,"user":{"displayName":"김대현","userId":"14081338161671999548"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["4. 모델 로드 및 커스터마이징  "],"metadata":{"id":"RL87hTcGFI14"}},{"cell_type":"code","source":["# 모델 로드 및 커스터마이징\n","model_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/classification/1\"\n","feature_extractor_layer = hub.KerasLayer(model_url, input_shape=(224, 224, 3), trainable=False)\n","\n","model = tf.keras.Sequential([\n","    feature_extractor_layer,\n","    tf.keras.layers.Dense(len(class_names), activation='softmax')  # 데이터셋에 맞는 출력 레이어 (클래스 수에 맞게 조정)\n","])\n","\n","model.compile(\n","    optimizer='adam',\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n"],"metadata":{"id":"QwJEg8N0Er-U","executionInfo":{"status":"ok","timestamp":1717690316078,"user_tz":-540,"elapsed":20376,"user":{"displayName":"김대현","userId":"14081338161671999548"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["5. 모델 훈련  "],"metadata":{"id":"5gLFCnykFMxQ"}},{"cell_type":"code","source":["# 모델 훈련\n","epochs = 5\n","history = model.fit(ds_train, validation_data=ds_val, epochs=epochs)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ekYH36jJEu4n","outputId":"13bd8cdc-ef76-4674-910e-5d1fb8cbacd3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","61/61 [==============================] - 550s 9s/step - loss: 1.9763 - accuracy: 0.9241 - val_loss: 1.8737 - val_accuracy: 1.0000\n","Epoch 2/5\n","61/61 [==============================] - 377s 6s/step - loss: 1.7791 - accuracy: 1.0000 - val_loss: 1.6821 - val_accuracy: 1.0000\n","Epoch 3/5\n","29/61 [=============>................] - ETA: 2:41 - loss: 1.6394 - accuracy: 1.0000"]}]},{"cell_type":"markdown","source":["6. ONNX로 모델 변환  "],"metadata":{"id":"g8EysAPDFQ_I"}},{"cell_type":"code","source":["# ONNX로 모델 변환\n","import tf2onnx\n","spec = (tf.TensorSpec((None, 224, 224, 3), tf.float32),)\n","output_path = \"efficientnet_b0.onnx\"\n","model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13)\n","with open(output_path, \"wb\") as f:\n","    f.write(model_proto.SerializeToString())"],"metadata":{"id":"eUVluCtyEw_9","executionInfo":{"status":"ok","timestamp":1717686209363,"user_tz":-540,"elapsed":16443,"user":{"displayName":"김대현","userId":"14081338161671999548"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["7. OpenVINO로 모델 최적화 및 추론  "],"metadata":{"id":"8OSa60POFVj4"}},{"cell_type":"code","source":["# OpenVINO로 모델 최적화 및 추론\n","from openvino.runtime import Core\n","\n","ie = Core()\n","model_onnx_path = \"/content/efficientnet_b0.onnx\"\n","model = ie.read_model(model=model_onnx_path)\n","compiled_model = ie.compile_model(model=model, device_name=\"CPU\")\n","\n","input_layer = compiled_model.input(0)\n","output_layer = compiled_model.output(0)\n","\n","# 이미지 전처리 함수\n","def preprocess_image_openvino(image_path):\n","    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n","    img = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n","    img = img.astype(np.float32)\n","    img = np.expand_dims(img, axis=0)  # 배치 차원 추가 (N, H, W, C)\n","    return img\n","\n","# OpenVINO 예측 함수\n","def predict_openvino(image_path):\n","    img = preprocess_image_openvino(image_path)\n","    predictions = compiled_model([img])\n","    predicted_class = np.argmax(predictions[output_layer], axis=-1)\n","    return class_names[predicted_class[0]]  # 예측된 클래스 이름 반환\n","\n","# 테스트 이미지 예측\n","image_path = \"/content/drive/MyDrive/Datas/test.jpg\"  # 여기에 테스트할 이미지 경로를 입력하세요.\n","predicted_class = predict_openvino(image_path)\n","print(f\"Predicted class: {predicted_class}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOnJgzUgE1Os","executionInfo":{"status":"ok","timestamp":1717686213284,"user_tz":-540,"elapsed":869,"user":{"displayName":"김대현","userId":"14081338161671999548"}},"outputId":"142ddc88-24ec-4a17-f59f-2b84ba5f72a1"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class: Bonobono\n"]}]},{"cell_type":"markdown","source":["8. ONNX 모델을 OpenVINO IR 형식으로 변환 \\\n","위의 명령어를 통해 ONNX 모델을 OpenVINO IR 형식으로 변환할 수 있습니다. 변환된 .xml 및 .bin 파일은 지정된 출력 디렉토리(/content/drive/MyDrive/efficientnet_model)에 저장됩니다."],"metadata":{"id":"ZiTn9KPkGGpG"}},{"cell_type":"code","source":["\n","# 모델 최적화를 위해 OpenVINO의 Model Optimizer 사용\n","!mo --input_model efficientnet_b0.onnx --output_dir /content/drive/MyDrive/efficientnet_model\n","\n","# 출력 디렉토리의 파일 목록 확인\n","!ls /content/drive/MyDrive/efficientnet_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GUkAU9RaE3lf","executionInfo":{"status":"ok","timestamp":1717686219926,"user_tz":-540,"elapsed":3516,"user":{"displayName":"김대현","userId":"14081338161671999548"}},"outputId":"accc557e-5525-43a9-b2d0-2c859f7fbcc5"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[ INFO ] Generated IR will be compressed to FP16. If you get lower accuracy, please consider disabling compression explicitly by adding argument --compress_to_fp16=False.\n","Find more information about compression to FP16 at https://docs.openvino.ai/2023.0/openvino_docs_MO_DG_FP16_Compression.html\n","[ INFO ] MO command line tool is considered as the legacy conversion API as of OpenVINO 2023.2 release. Please use OpenVINO Model Converter (OVC). OVC represents a lightweight alternative of MO and provides simplified model conversion API. \n","Find more information about transition from MO to OVC at https://docs.openvino.ai/2023.2/openvino_docs_OV_Converter_UG_prepare_model_convert_model_MO_OVC_transition.html\n","[ SUCCESS ] Generated IR version 11 model.\n","[ SUCCESS ] XML file: /content/drive/MyDrive/efficientnet_model/efficientnet_b0.xml\n","[ SUCCESS ] BIN file: /content/drive/MyDrive/efficientnet_model/efficientnet_b0.bin\n","efficientnet_b0.bin  efficientnet_b0.xml\n"]}]}]}